---
title: "HarvardX:PH125.9x Data Science: Capstone: MovieLens Recommendation System"
author: "Richard Jonyo"
date: "19 February 2022"
output:
  html_document:
  pdf_document: default
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1. Executive Summary
The goal of this project was to come up with a movie recommendation system using the MovieLens datasets which consists of 10 million movie ratings. A movie recommendation system is an information filtering system that attempts to predict the rating or preference a user would give to a movie. Recommendation systems are an improvement over the traditional classification models as they can take many classes of input and provide similarity ranking based on algorithms hence providing the user with more accurate results.

This project is part of the HarvardX:PH125.9x Data Science: Capstone course and we use a smaller subset of the [MovieLens](https://grouplens.org/datasets/movielens/10m/) dataset which is 10M that contains 10,677 movies by 69,878 users. The dataset has genres, and the movies are rated from 0.5 to 5 with increments of 0.5. A movie can be categorized under a number of genres.

The dataset is split into two sets: a training set (edx) and a final hold-out test set (validation) using code provided by the course. The objective was for the final algorithm to predict ratings with a root mean square error (RMSE) of less than 0.86490 versus the actual ratings included in the validation set.

To develop the recommendation model, a 4-step approach was employed where the initial model assumed the recommendations agreed with the naive mean of all movie ratings. The second model added the movie bias to the initial model since some movies seem to be more popular than others. The third model added users bias which improved the RMSE slightly. The final model included the regularized movie and user biases to improve the RMSE.

Exploratory analysis was conducted on the data using R and R Studio, a language and a software environment for statistical computing. R Markdown, a simple formatting syntax for authoring HTML, PDF, and MS Word documents and a component of R Studio was used to compile the report.

# 2. Methods and Exploratory Analysis
This sections helps us to understand the structure of the Movilens dataset for us to gain insights that will aid in a better prediction of movie ratings. It explains the process and techniques used, including data cleaning, exploration, visualization, insights gained, and the modeling approach used.

### Required libraries
The project utilized and loaded several CRAN libraries to assist with our analysis. The libraries were automatically downloaded and installed during code execution. These included: tidyverse, caret, data.table, lubridate, and dplyr libraries.


```{r Loading Packages, message = FALSE, warning = FALSE}
# Note: this process could take a couple of minutes
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")

library(tidyverse)
library(caret)
library(data.table)
library(lubridate)
library(dplyr)
```

### The MovieLens dataset
The Movielens Dataset (25M) contains 25 million ratings and one million tag applications applied to 62,000 movies by 162,000 users. The dataset has no demographic information. Each user is represented by an id and no other information about the users is provided. For this project we use the Movielens Dataset (10M) which is a subset of the full dataset. Edx is the name provided to the subset of the MovieLens dataset that consists of 9,000,055 observations and 6 columns. Each observation is a rating provided by a user for a movie. The dataset contains ratings provided by a total of 69,878 unique users for a total of 10,677 unique movies. Below is the code that was provided by the course so that this project can build on it.

```{r LoadingDataset, message = FALSE, warning = FALSE}
# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")

# We are using R 4.0.4:
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(movieId),
                                           title = as.character(title),
                                           genres = as.character(genres))


movielens <- left_join(ratings, movies, by = "movieId")

# Our validation set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding") # if using R 3.5 or earlier, use `set.seed(1)`
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)
```

### Splitting the edx dataset
The edx dataset is divided into two sets: training and test datasets. The test_dataset is used to evaluate model when building the model. The training set has 8,100,048 observations and 6 columns. The validation set which represents 10% of the 10M Movielens dataset has the same features, but with a total of 899,993 occurrences and it is used to evaluate the final model.

```{r Splitting Dataset, message = FALSE, warning = FALSE}
#We divide into two sets: training and test sets
#The test set will be split into two
#test_dataset: to evaluate and test the model when building the model
#validation: to evaluate the final model
test_dataset <- createDataPartition(y = edx$rating, times = 1, p = 0.1, list = FALSE)
training_dataset <- edx[-test_dataset,]
temp <- edx[test_dataset,]
dim(training_dataset) #training set has 8,100,048 records
```

We ensure that the userId and movieId are in both training and test sets

```{r Add UserId and MovieId, message = FALSE, warning = FALSE}
test_dataset <- temp %>%
  semi_join(training_dataset, by = "movieId") %>%
  semi_join(training_dataset, by = "userId") 

# We add the rows removed from or test dataset into training set
removed_rows <- anti_join(temp, test_dataset)
training_dataset <- rbind(training_dataset, removed_rows)
```

### Exploratory Analysis
We need to understand the edx dataset before starting to develop the models hence an exploratory analysis is significant.

Below is a quick summary (top five records), and the data types of the dataset:
```{r Summary of edx, message = FALSE, warning = FALSE}
head(edx, 5) #Preview edx
knitr::kable(summary(edx))           
```

The columns in the edx dataset include userId, movieId, rating, timestamp, title, and genres.
```{r, echo=FALSE}
glimpse(edx, width = 50) #view data types of edx
```

There are no missing values
```{r Missing Values, message = FALSE, warning = FALSE}
anyNA(edx) #check missing values - results to FALSE
```

We have 69,878 users and 10,677 movies in the edx set
```{r, include=TRUE, echo=FALSE}
edx %>% summarize(n_users = n_distinct(userId), n_movies = n_distinct(movieId))
```

### Movie ratings
Pulp Fiction (1994), Forrest Gump (1994) and Silence of the Lambs (1991) are the highest rated in that order with over 30,000 ratings.The average rating in the edx dataset was `r round(mean(edx$rating), 2)`. The minimum rating for the movies was `r min(edx$rating)` and the maximum rating was `r max(edx$rating)`.

```{r, echo=FALSE}
unique(edx$rating) 
```

The figure below show the top 10 most popular movies.

```{r Movie Ratings, message = FALSE, warning = FALSE}
#plotting top 10 most popular movies
edx %>%
  group_by(title) %>%
  summarize(count = n()) %>%
  arrange(-count) %>%
  top_n(10, count) %>%
  ggplot(aes(count, reorder(title, count))) +
  geom_bar(color = "black", fill = "brown", stat = "identity") +
  ggtitle("Top 10 most popular movies")+
  theme(plot.title = element_text(hjust = 0.5))+
  xlab("Count of ratings") +
  ylab(NULL) 
```

The figure below shows is the distribution of movie ratings. The average rating in the edx dataset was 3.512465. The minimum rating for a movie was 0.5 and the maximum rating was 5.0. Some movies ratings fall below the average rating, and some are above. We can see that there is a bias for some movies which makes their ratings deviate from the mean rating.

```{r Plot: Rating Distribution, message = FALSE, warning = FALSE}
mean = mean(edx$rating)#mean

# We visualize the training set rating distribution
edx %>% 
ggplot(aes(rating, y = ..prop..)) +
  geom_bar(fill = "brown") +
  ggtitle("Training set rating distribution")+
  theme(plot.title = element_text(hjust = 0.5))+
  scale_x_continuous(breaks = c(0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5))+ 
  labs(x = "Movie rating", y = "No. of ratings")
```

### Users rating
The plot below shows the distribution of the number of ratings by users. We notice that users do not have a uniform average rating. Users may have a bias towards particular movies and some may have a tendency to rate a movie high or less.

```{r Plot: Ratings by Users, message = FALSE, warning = FALSE}
#We plot the no. of ratings by users
edx %>% 
  count(userId) %>% 
  ggplot(aes(n, fill = "brown")) + 
  geom_histogram( bins=30, color="black", show.legend = FALSE) +
  scale_x_log10() +
  labs(x = "Users", y = "Number of ratings")+
  ggtitle("Distribution of number of ratings by users")+
  theme(plot.title = element_text(hjust = 0.5))
```

We plot mean rating by users and it is evident that the distribution of the average ratings is right-skewed, meaning that many users tend to provide good ratings.

```{r Plot: Mean Rating by Users, message = FALSE, warning = FALSE}
#We plot mean rating by users
edx %>% group_by(userId) %>%
  summarise(mean_rating = sum(rating)/n()) %>%
  ggplot(aes(mean_rating, fill = "brown")) +
  geom_histogram( bins=30, color="black", show.legend = FALSE) +
  labs(x = "Average rating", y = "Number of users")+
  ggtitle("Distribution of average ratings by users")+
  theme(plot.title = element_text(hjust = 0.5))
```

### Year of release
We need to extract the year of release in the edx dataset into a separate column that will be of a more usable format.

```{r, echo=FALSE}
#We have the release year from the title into a separate column
edx <- edx %>% mutate(release_year = as.numeric(str_extract(str_extract(title, "[/(]\\d{4}[/)]$"), regex("\\d{4}"))),title = str_remove(title, "[/(]\\d{4}[/)]$"))
```

The figure below shows the movie ratings over the years. We can see that prior to 1990s movies were highly rated than between the years 1930 and 1970. After 1970, the movie ratings decreased gradually.

```{r Plot - Rating over Years, message = FALSE, warning = FALSE}
#Plot for average rating through the years
edx %>% group_by(release_year) %>%
  summarise(n =n(), avg = mean(rating)) %>%
  ggplot(aes(release_year, avg))+
  geom_point()+geom_hline(yintercept = mean, color = "red")+labs(x="Release Year",y="Average rating")+theme(axis.text = element_text(size=12,face = "bold"))+
  ggtitle('Average rating through the years')+
  theme(plot.title = element_text(hjust = 0.5))
  
```

### Genre
The top 3 movie genres which were highly reviewed were Drama (733,296), Comedy (700,889), and Comedy|Romance (365,468)

```{r Summary: Top 3 Genre, message = FALSE, warning = FALSE}
#Top 3 movie genres which were highly reviewed
top_genres <- edx %>% group_by(genres) %>% 
  summarize(count = n()) %>% arrange(desc(count)) %>% head(3)
top_genres %>% knitr::kable()
```

The figure below shows a summary of the genres by year.

```{r Summary - Popular Genre by Year, message = FALSE, warning = FALSE}
#We summarize the popular genres by year
genres_by_year <- edx %>% 
  separate_rows(genres, sep = "\\|") %>% 
  select(movieId, release_year, genres) %>% 
  group_by(release_year, genres) %>% 
  summarise(count = n()) %>% arrange(desc(release_year)) 
```


Different periods show certain genres being more popular during those periods. It is for this reason that we will not include genre into our prediction model. Majority of the ratings were done between the years 1990 and 2010.

```{r Plot: Genre by Year, message = FALSE, warning = FALSE}
ggplot(genres_by_year, aes(x = release_year, y = count)) + 
  geom_col(aes(fill = genres), position = 'dodge') + 
  ylab('No. of movies') + 
  xlab('Release year') + 
  ggtitle('Popularity/year by genre')+
  theme(plot.title = element_text(hjust = 0.5))
```


# 3. Results
This section presents the prediction approach that was employed, modeling results and discusses the model performance.

### The Prediction Approach
The accuracy was evaluated using the RMSE which measures the difference between predicted and observed values. Our goal is to reduce the error below 0.8649.The RMSE function was defined as follows:


```{r Function: RMSE, message = FALSE, warning = FALSE}
#function to compute RMSE
rmse <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2))
}
```

#### First Model (naive model)

For the first model we make a prediction using the mean of the movie ratings. Also known as the naive model which assumes the movies will have the same rating regardless of genre or user. The mean obtained was `mean_movie_rating` and RMSE = `first_rmse`.
```{r, echo=FALSE}
mean_movie_rating <- mean(training_dataset$rating)
mean_movie_rating
```

We obtain our first RMSE = 1.060242. The error is greater than 1 hence lacks accuracy. Our Second Model will attempt to improve the error.

```{r Model 1 - Naive Model, message = FALSE, warning = FALSE}
first_rmse <- rmse(test_dataset$rating, mean_movie_rating)

#Save RMSE result in a dataframe
results = data_frame(method = "Model 1: Using the mean (Naive model)", RMSE = first_rmse)
results %>% knitr::kable()
```

We can confirm that some movies are more popular than others hence creating a bias. There seems to be is a slight improvement on our second model where there RMSE = `second_rmse`.

#### Second Model (movie bias)
```{r MOdel 2 - Movie Bias, message = FALSE, warning = FALSE}
#We include bias_1 to represent the mean rating of the movies
movie_bias <- training_dataset %>%
  group_by(movieId) %>%
  summarize(bias_1 = mean(rating - mean_movie_rating))

#We plot movie bias
movie_bias %>% ggplot(aes(bias_1)) +
  geom_histogram(color = "black", fill = "brown", bins = 20) +
  xlab("Movie bias") +
  ylab("Count (n)")+
  ggtitle("Movie effect")+
  theme(plot.title = element_text(hjust = 0.5))

#Testing RMSE by adding the movie bias to our second model
#There is a slight improvement on our second model
predictions <- mean_movie_rating + training_dataset %>%
  left_join(movie_bias, by = "movieId") %>%
  pull(bias_1)
second_rmse <- rmse(predictions, test_dataset$rating)
results <- bind_rows(results,
                          data_frame(method="Model 2: Mean + movie bias",
                                     RMSE = second_rmse))
results %>% knitr::kable()
```

#### Third Model (movie & user biases)
As seen previously users can add bias by rating some movies very highly or very low. These extreme ratings adds this bias to our mode. Having included movie and user biases the error is slightly lower where there RMSE = `third_rmse`.

```{r MOdel 3 - Movie & User Bias, message = FALSE, warning = FALSE}
users_bias <- training_dataset %>%
  left_join(movie_bias, by = "movieId") %>%
  group_by(userId) %>%
  summarize(bias_2 = mean(rating - mean_movie_rating - bias_1))

#We plot movie + User bias
users_bias %>% ggplot(aes(bias_2)) +
  geom_histogram(color = "black", fill = "brown", bins = 20) +
  xlab("User and movie bias") +
  ylab("Count (n)")+
  ggtitle("Movie + User effect")+
  theme(plot.title = element_text(hjust = 0.5))

predictions <- test_dataset %>%
  left_join(movie_bias, by = "movieId") %>%
  left_join(users_bias, by = "userId") %>%
  mutate(new_pred = mean_movie_rating + bias_1 + bias_2) %>%
  pull(new_pred)
  third_rmse <- RMSE(predictions, test_dataset$rating)
  results <- bind_rows(results,
                       data_frame(method="Model 3: Mean + movie + user bias",
                                  RMSE = third_rmse))
  results %>% knitr::kable()
```
  
#### Fourth Model (regularized movie & user biases)
Some movies are rated by very few users, this can increase RMSE. Regularization allows for reduced errors caused by movies with few ratings which can influence the prediction and eventually influence the error. The final RMSE obtained for our final model was `fourth_rmse` which is less than the target RMSE of 0.86490 hence providing a better accuracy.
  
```{r MOdel 4 - Regularized, Movie & User Bias, message = FALSE, warning = FALSE}
  lambdas <- seq(from=0, to=10, by=0.25)
  rmses <- sapply(lambdas, function(x){
    
     #Adjust mean by movie effect and penalize low number on ratings
    movie_bias <- training_dataset %>%
      group_by(movieId) %>%
      summarize(movie_bias = sum(rating - mean_movie_rating)/(n()+x))
    
    #Adjust mean by user + movie effect and penalize low number of ratings
    user_bias <- training_dataset %>%
      left_join(movie_bias, by = "movieId") %>%
      group_by(userId) %>%
      summarize(user_bias = sum(rating - movie_bias - mean_movie_rating)/(n()+x))
    predictions <- test_dataset %>%
      left_join(movie_bias, by = "movieId") %>%
      left_join(user_bias, by = "userId") %>%
      mutate(new_pred = mean_movie_rating + movie_bias + user_bias) %>%
      pull(new_pred)
    return(rmse(predictions, test_dataset$rating))
  })
```
  
We plotted RMSE against lambdas to obtain optimal lambda. According to the plot below lambda at `lamd` produced the lowest RMSE.
  
```{r Plot: Lamdas, message = FALSE, warning = FALSE}
  qplot(lambdas, rmses, color = I("brown")) 

  #We calculate the regularized accuracy with the best lambda
  lamd <- lambdas[which.min(rmses)] #best lamda
  lamd
  
  movie_bias <- edx %>% 
    group_by(movieId) %>%
    summarize(movie_bias = sum(rating - mean_movie_rating)/(n()+lamd))

  user_bias <- edx %>% 
    left_join(movie_bias, by="movieId") %>%
    group_by(userId) %>%
    summarize(user_bias = sum(rating - movie_bias - mean_movie_rating)/(n()+lamd))
  
  predictions <- test_dataset %>% 
    left_join(movie_bias, by = "movieId") %>%
    left_join(user_bias, by = "userId") %>%
    mutate(new_pred = mean_movie_rating + movie_bias + user_bias) %>%
    pull(new_pred)
  fourth_rmse <- rmse(predictions, test_dataset$rating)
  results <- bind_rows(results,
                       data_frame(method="Model 4: Mean + movie + user bias + Regularisation",
                                  RMSE = fourth_rmse))
  results %>% knitr::kable()
  
``` 
  
# 4. Conclusion 
We employed a 4-step approach to come up with a movie recommendation model. The final model (fourth model) is the preferred movie recommendation model since its RMSE is `fourth_rmse` which is below the target of 0.8649. The limitations of this project included having movies that were rated by a small number of users which were not credible enough. Similarly, users who rated only a small number of movies should not be taken into account to remove the biases. Preferably we should only consider users who have given at least 50 ratings. It is also suggested that other data such as age, user behavior, gender, etc. could further enhance the final model.



  


---
title: "HarvardX:PH125.9x Data Science: Capstone: MovieLens Recommendation System"
author: "Richard Jonyo"
date: "19 February 2022"

---
